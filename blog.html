<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mi Blog</title>
    <link rel="stylesheet" href="./css/main.css">
    <link rel="stylesheet" href="./css/font/flaticon.css">
    <link rel="stylesheet" href="/css/media-queries.css">
</head>
<body>
    <header>

        <section class="header-icons-container">
            <div class="icons">
                <a href="https://www.facebook.com/jmt.inthehause/"><span class="flaticon-001-facebook"></span></a>
                <a href="https://twitter.com/Jesus_M_tavarez"><span class="flaticon-002-twitter"></span></a>
                <a href="https://www.youtube.com/@onebeattheproducer4310"><span class="flaticon-008-youtube"></span></a>
                <a href="https://img.shields.io/static/v1?message=LinkedIn&logo=linkedin&label=&color=0077B5&logoColor=white&labelColor=&style=for-the-badge"><span class="flaticon-010-linkedin"></span></a>
                <a href=""><span class="flaticon-013-twitter-1:before"></span></a>
                <a href="https://www.instagram.com/jmtenlacasa/"><span class="flaticon-011-instagram"></span></a>
            </div>
        </section>
        <nav>
            <section class="nav-logo-container">
                <a href="7"> <img src="/assets/img/Logo-negro.png" alt=""> </a>
            </section>
            <section class="profile-link">
                <a href="./perfil.html">About me</a>
            </section>
        </nav>
    </header>
    <main>
        <section class=" grid-container blogpost-img-container">
            <img src="/assets/img/iai.jpg" alt="">
        </section>
        <section class="blogpost-main-container">
            <div class="grid-container">
                <h3>Articolo</h3>
                <article>
                    <h1>L'IA può portare all'estinzione, l'allerta di decine di ricercatori</h1>
                    <p>L'intelligenza artificiale potrebbe portare all'estinzione dell'umanità: è l'avvertimento di esperti del settore tra cui Sam Altman, ad del produttore di ChatGPT OpenAI, Demis Hassabis, amministratore delegato di Google DeepMind e Dario Amodei di Anthropic.
                    "Mitigare il rischio di estinzione dell'Intelligenza artificiale dovrebbe essere una priorità globale insieme ad altri rischi su scala sociale come le pandemie e la guerra nucleare": è la dichiarazione pubblicata sulla pagina web del Center for AI Safety, un'organizzazione americana che riunisce esperti attivi nel settore.
                    Tra i firmatari anche alcuni italiani, tra cui il fisico Roberto Battiston dell'Universitàdi Trento e Luca Simoncini, ex docente di Ingegneria dell'informazione all'Università di Pisa ed ex direttore dell'Istituto di tecnologie dell'informazione del Consiglio Nazionale delle Ricerche.
                    </p>
                    <p>"Non si tratta della minaccia di una super intelligenza che possa sopraffare l'umanità, ma delle conseguenze del modo con cui gli esseri umani si abitueranno a utilizzare questi algoritmi nel loro lavoro e nella vita quotidiana della società", dice Battiston. "Pensiamo ad esempio - aggiunge - alla possibile interferenza sui processi elettorali, alla diffusione di notizie false, alla creazione di canali di notizie che rispondono a precisi interessi di disinformazione". Per questo, "occorre prepararsi a gestire queste situazioni, le prime avvisaglie di problemi di questo genere le abbiamo già viste negli anni passati con la vicenda di Cambridge Analytica o con la tattiche di guerriglia dei troll russi sul web".</p>
                    <p>"L'uso estensivo dell'intelligenza artificiale da un lato sta portando a una vera rivoluzione e dall'altro sta ponendo seri problemi", osserva Simoncini. "L'intelligenza artificiale è così pervasiva da avere un forte impatto in molti settori della vita sociale (pensiamo solo al rischio di produzione di fake news o al controllo delle auto autonome), come su aspetti economici, finanziari, politici, educativi ed etici", osserva l'esperto. "E' evidente - aggiunge - che nessuno può opporsi se una tecnologia emergente è usata per scopi benefici, per esempio in campo biomedico o farmacologico". Di conseguenza, se parlare di rischio di estinzione dell'umanità può sembrare un'iperbole secondo Simoncini la dichiarazione del Cias ricorda il manifesto nel quale Bertrand Russell e Albert Einstein nel 1955 denunciavano i rischi delle armi nucleari.</p>
                </article>
            </div>
        </section>
        <section class="contact-main-container">
            <div>
                <img src="/assets/img/013-newsletter.png" alt="">
                <div class="contact-left">
                    <a href="">Subcribiti</a>
                    <p>Non perderti tutte le novita</p>
                </div>
            </div>
            <div>
                <img src="/assets/img/006-like.png" alt="">
                <div class="contact-right">
                    <a href="">Contatti</a>
                    <p>Scribici hai nostri contatti</p>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>AGENZIA ANSA - periodicità quotidiana - Iscrizione al Registro della Stampa presso il Tribunale di Roma n. 212/1948
            P.I. IT00876481003 - © Copyright ANSA - Tutti i diritti riservati</p>
    </footer>
</body>
</html>